{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following Travis' Data Cleaning Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    id_student code_module  score Gender                Region  \\\n",
      "0        11391         AAA   82.0      M   East Anglian Region   \n",
      "1        28400         AAA   66.4      F              Scotland   \n",
      "3        31604         AAA   76.0      F     South East Region   \n",
      "4        32885         AAA   54.4      F  West Midlands Region   \n",
      "5        38053         AAA   68.0      M                 Wales   \n",
      "6        45462         AAA   68.0      M              Scotland   \n",
      "7        45642         AAA   72.4      F  North Western Region   \n",
      "8        52130         AAA   71.4      F   East Anglian Region   \n",
      "9        53025         AAA   78.0      M          North Region   \n",
      "10       57506         AAA   74.0      M          South Region   \n",
      "\n",
      "                            HLE Age group  Credit Distribution  \\\n",
      "0              HE Qualification      55<=                  240   \n",
      "1              HE Qualification     35-55                   60   \n",
      "3         A Level or Equivalent     35-55                   60   \n",
      "4            Lower Than A Level      0-35                   60   \n",
      "5         A Level or Equivalent     35-55                   60   \n",
      "6              HE Qualification      0-35                   60   \n",
      "7         A Level or Equivalent      0-35                  120   \n",
      "8         A Level or Equivalent      0-35                   90   \n",
      "9   Post Graduate Qualification      55<=                   60   \n",
      "10           Lower Than A Level     35-55                   60   \n",
      "\n",
      "    assessment_completion_ratio  total_vle_clicks  target  \n",
      "0                      0.833333             934.0       1  \n",
      "1                      0.833333            1435.0       1  \n",
      "3                      0.833333            2158.0       1  \n",
      "4                      0.833333            1034.0       1  \n",
      "5                      0.833333            2445.0       1  \n",
      "6                      0.833333            1492.0       1  \n",
      "7                      0.833333            1428.0       1  \n",
      "8                      0.833333            1894.0       1  \n",
      "9                      0.833333            3158.0       1  \n",
      "10                     0.833333            1319.0       1  \n",
      "Number of rows in df_final: 22437\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score, classification_report, confusion_matrix, f1_score\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# ============================\n",
    "# Data Loading and Merging\n",
    "# ============================\n",
    "\n",
    "# 1. Load your CSV files into DataFrames\n",
    "df_assessments = pd.read_csv(\"assessments.csv\")\n",
    "df_courses = pd.read_csv(\"courses.csv\")\n",
    "df_studentAssessment = pd.read_csv(\"studentAssessment.csv\")\n",
    "df_studentInfo = pd.read_csv(\"studentInfo.csv\")\n",
    "df_studentRegistration = pd.read_csv(\"studentRegistration.csv\")\n",
    "df_studentVle = pd.read_csv(\"studentVle.csv\")\n",
    "df_vle = pd.read_csv(\"vle.csv\")\n",
    "\n",
    "# Count how many unique assessments exist for each module + presentation\n",
    "df_course_assess_count = (\n",
    "    df_assessments\n",
    "    .groupby([\"code_module\", \"code_presentation\"])[\"id_assessment\"]\n",
    "    .count()\n",
    "    .reset_index()\n",
    "    .rename(columns={\"id_assessment\": \"total_assessments\"})\n",
    ")\n",
    "\n",
    "# Count how many assessments each student attempted\n",
    "df_attempted_count = (\n",
    "    df_studentAssessment\n",
    "    .groupby(\"id_student\")[\"id_assessment\"]\n",
    "    .count()\n",
    "    .reset_index()\n",
    "    .rename(columns={\"id_assessment\": \"num_assessments_attempted\"})\n",
    ")\n",
    "\n",
    "# Compute average score for each student\n",
    "df_avg_score = (\n",
    "    df_studentAssessment\n",
    "    .groupby(\"id_student\")[\"score\"]\n",
    "    .mean()  \n",
    "    .reset_index()\n",
    "    .rename(columns={\"score\": \"score\"})\n",
    ")\n",
    "\n",
    "df_vle_clicks = (\n",
    "    df_studentVle\n",
    "    .groupby(\"id_student\")[\"sum_click\"]\n",
    "    .sum()\n",
    "    .reset_index()\n",
    "    .rename(columns={\"sum_click\": \"total_vle_clicks\"})\n",
    ")\n",
    "\n",
    "# Merge data\n",
    "df_merged = df_studentInfo.merge(df_course_assess_count, on=[\"code_module\", \"code_presentation\"], how=\"left\")\n",
    "df_merged = df_merged.merge(df_attempted_count, on=\"id_student\", how=\"left\")\n",
    "df_merged = df_merged.merge(df_avg_score, on=\"id_student\", how=\"left\")\n",
    "df_merged = df_merged.merge(df_vle_clicks, on=\"id_student\", how=\"left\")\n",
    "\n",
    "# Replace NaN with 0 where necessary\n",
    "df_merged.fillna({\"num_assessments_attempted\": 0, \"total_assessments\": 0, \"score\": 0, \"total_vle_clicks\": 0}, inplace=True)\n",
    "\n",
    "# Compute assessment completion ratio\n",
    "df_merged[\"assessment_completion_ratio\"] = np.where(\n",
    "    df_merged[\"total_assessments\"] == 0, 0, df_merged[\"num_assessments_attempted\"] / df_merged[\"total_assessments\"]\n",
    ")\n",
    "\n",
    "# Filter out withdrawn students\n",
    "df_merged = df_merged[df_merged[\"final_result\"] != \"Withdrawn\"].copy()\n",
    "\n",
    "# Create binary target (Pass/Distinction=1, Fail=0)\n",
    "df_merged[\"target\"] = df_merged[\"final_result\"].apply(lambda x: 1 if x in [\"Pass\", \"Distinction\"] else 0)\n",
    "\n",
    "# Rename columns for clarity\n",
    "df_merged.rename(\n",
    "    columns={\n",
    "        \"highest_education\": \"HLE\",\n",
    "        \"age_band\": \"Age group\",\n",
    "        \"studied_credits\": \"Credit Distribution\",\n",
    "        \"gender\": \"Gender\",\n",
    "        \"region\": \"Region\"\n",
    "    },\n",
    "    inplace=True\n",
    ")\n",
    "\n",
    "# Select final dataset columns\n",
    "df_final = df_merged[\n",
    "    [\n",
    "        \"id_student\",\n",
    "        \"code_module\",\n",
    "        \"score\",\n",
    "        \"Gender\",\n",
    "        \"Region\",\n",
    "        \"HLE\",\n",
    "        \"Age group\",\n",
    "        \"Credit Distribution\",\n",
    "        \"assessment_completion_ratio\",\n",
    "        \"total_vle_clicks\",\n",
    "        \"target\"\n",
    "    ]\n",
    "].copy()\n",
    "\n",
    "print(df_final.head(10))\n",
    "print(\"Number of rows in df_final:\", len(df_final))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Baseline Logistic Regression Model**\n",
    "✅ This is the **initial Logistic Regression model** without feature selection or hyperparameter tuning.  \n",
    "✅ The model includes **all available features**, encoding categorical variables and standardizing numerical features.  \n",
    "✅ **Class imbalance** is handled using `class_weight='balanced'` and **sample weighting** based on `code_module`.\n",
    "\n",
    "#### **Model Performance**\n",
    "- **Accuracy**: **86.13%**\n",
    "\n",
    "- **Balanced Accuracy**: **82.21%**\n",
    "- **F1 Score**: **90.17%**\n",
    "- **Confusion Matrix**:\n",
    "  - **False Positives (FP)**: 500\n",
    "\n",
    "  - **False Negatives (FN)**: 278\n",
    "\n",
    "#### **Key Observations**\n",
    "- **Top Features:** `score`, `assessment_completion_ratio`, `total_vle_clicks` are the most important.\n",
    "\n",
    "- **Potential Weak Features:** Features like `Region_Ireland`, `Age group_55<=`, and `HLE_Lower Than A Level` have very small or negative coefficients.\n",
    "- **High False Positives (500)**: Many students predicted to pass actually failed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Logistic Regression Accuracy: 0.861319073083779\n",
      "Logistic Regression Balanced Accuracy: 0.8220642054323772\n",
      "Logistic Regression F1 Score: 0.9017180394138454\n",
      "Logistic Regression Confusion Matrix:\n",
      " [[1263  500]\n",
      " [ 278 3569]]\n",
      "\n",
      "Feature Importance (Logistic Regression):\n",
      "                             Feature  Coefficient\n",
      "0                             score     0.486091\n",
      "2       assessment_completion_ratio     0.474513\n",
      "3                  total_vle_clicks     0.276513\n",
      "21                  Age group_35-55     0.045876\n",
      "17             HLE_HE Qualification     0.028118\n",
      "12              Region_South Region     0.020358\n",
      "11         Region_South East Region     0.018864\n",
      "28                  code_module_GGG     0.017708\n",
      "13         Region_South West Region     0.015112\n",
      "22                   Age group_55<=     0.008806\n",
      "8               Region_North Region     0.008751\n",
      "5       Region_East Midlands Region     0.008569\n",
      "20  HLE_Post Graduate Qualification     0.004521\n",
      "6                    Region_Ireland     0.001465\n",
      "26                  code_module_EEE    -0.000336\n",
      "19              HLE_No Formal quals    -0.002003\n",
      "15      Region_West Midlands Region    -0.002439\n",
      "23                  code_module_BBB    -0.003120\n",
      "16          Region_Yorkshire Region    -0.004690\n",
      "7              Region_London Region    -0.006261\n",
      "9       Region_North Western Region    -0.015076\n",
      "14                     Region_Wales    -0.018825\n",
      "10                  Region_Scotland    -0.028495\n",
      "25                  code_module_DDD    -0.035054\n",
      "27                  code_module_FFF    -0.042685\n",
      "4                          Gender_M    -0.042972\n",
      "1               Credit Distribution    -0.043675\n",
      "24                  code_module_CCC    -0.054397\n",
      "18           HLE_Lower Than A Level    -0.085372\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------------\n",
    "# Define Features and Target\n",
    "# -----------------------------------\n",
    "features = [\n",
    "    'score', 'Gender', 'Region', 'HLE', 'Age group',\n",
    "    'Credit Distribution', 'assessment_completion_ratio', 'total_vle_clicks',\n",
    "    'code_module'  # Include module as a feature\n",
    "]\n",
    "\n",
    "X = df_final[features]\n",
    "y = df_final['target']\n",
    "\n",
    "# -----------------------------------\n",
    "# One-hot Encoding of Categorical Features\n",
    "# -----------------------------------\n",
    "X_encoded = pd.get_dummies(\n",
    "    X, \n",
    "    columns=['Gender', 'Region', 'HLE', 'Age group', 'code_module'], \n",
    "    drop_first=True\n",
    ")\n",
    "\n",
    "# -----------------------------------\n",
    "# Standardize Numerical Features\n",
    "# -----------------------------------\n",
    "scaler = StandardScaler()\n",
    "numerical_features = ['score', 'Credit Distribution', 'assessment_completion_ratio', 'total_vle_clicks']\n",
    "X_encoded[numerical_features] = scaler.fit_transform(X_encoded[numerical_features])\n",
    "\n",
    "# -----------------------------------\n",
    "# Create Sample Weights by Module\n",
    "# -----------------------------------\n",
    "# Compute module counts and assign a weight = 1 / count for each sample\n",
    "module_counts = df_final['code_module'].value_counts()\n",
    "df_final['module_weight'] = df_final['code_module'].map(lambda m: 1.0 / module_counts[m])\n",
    "sample_weights = df_final['module_weight']\n",
    "\n",
    "# -----------------------------------\n",
    "# Split Data into Training and Test Sets\n",
    "# -----------------------------------\n",
    "X_train, X_test, y_train, y_test, w_train, w_test = train_test_split(\n",
    "    X_encoded, y, sample_weights, test_size=0.25, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# -----------------------------------\n",
    "# Logistic Regression with Class Weights and Sample Weights\n",
    "# -----------------------------------\n",
    "clf_lr = LogisticRegression(\n",
    "    max_iter=1000, \n",
    "    class_weight='balanced',  # Addressing class imbalance\n",
    "    random_state=42\n",
    ")\n",
    "clf_lr.fit(X_train, y_train, sample_weight=w_train)\n",
    "y_pred_lr = clf_lr.predict(X_test)\n",
    "\n",
    "# -----------------------------------\n",
    "# Model Evaluation for Logistic Regression\n",
    "# -----------------------------------\n",
    "accuracy_lr = accuracy_score(y_test, y_pred_lr)\n",
    "balanced_accuracy_lr = balanced_accuracy_score(y_test, y_pred_lr)\n",
    "f1_lr = f1_score(y_test, y_pred_lr)\n",
    "cm_lr = confusion_matrix(y_test, y_pred_lr)\n",
    "\n",
    "print(\"\\nLogistic Regression Accuracy:\", accuracy_lr)\n",
    "print(\"Logistic Regression Balanced Accuracy:\", balanced_accuracy_lr)\n",
    "print(\"Logistic Regression F1 Score:\", f1_lr)\n",
    "print(\"Logistic Regression Confusion Matrix:\\n\", cm_lr)\n",
    "\n",
    "# -----------------------------------\n",
    "# Feature Importance\n",
    "# -----------------------------------\n",
    "feature_importance = pd.DataFrame({\n",
    "    \"Feature\": X_encoded.columns,\n",
    "    \"Coefficient\": clf_lr.coef_[0]\n",
    "}).sort_values(by=\"Coefficient\", ascending=False)\n",
    "\n",
    "print(\"\\nFeature Importance (Logistic Regression):\\n\", feature_importance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Logistic Regression After Feature Selection**\n",
    "✅ **Dropped weak features** (`Region_Ireland`, `HLE_Lower Than A Level`, `Age group_55<=`) based on low feature importance.  \n",
    "✅ **Re-standardized numerical features** to maintain consistency after dropping features.  \n",
    "✅ **Retrained the model** to check performance improvements.\n",
    "\n",
    "#### **Model Performance After Dropping Weak Features**\n",
    "- **Accuracy**: **84.67%** ⬇ (**slight decrease** from 86.13%)\n",
    "\n",
    "- **Balanced Accuracy**: **83.68%** ⬆ (**improved generalization**)\n",
    "- **F1 Score**: **88.54%**\n",
    "- **Confusion Matrix**:\n",
    "  - **False Positives (FP)**: **335** ⬇ (**Better than before**)\n",
    "\n",
    "  - **False Negatives (FN)**: **525** ⬆ (**Worsened**)\n",
    "\n",
    "#### **Key Observations**\n",
    "- **Balanced Accuracy improved** → The model performs more evenly across pass/fail classes.\n",
    "\n",
    "- **False Negatives increased** → More failing students were misclassified as passing.\n",
    "- **Feature Importance changed** → The impact of `score` and `assessment_completion_ratio` increased after dropping weaker features.\n",
    "- **Next Step:** Tune hyperparameter `C` to reduce false negatives while maintaining balanced accuracy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Performance After Dropping Weak Predictors:\n",
      "Logistic Regression Accuracy: 0.8467023172905526\n",
      "Logistic Regression Balanced Accuracy: 0.8367565034728095\n",
      "Logistic Regression F1 Score: 0.8853944562899787\n",
      "Logistic Regression Confusion Matrix:\n",
      " [[1428  335]\n",
      " [ 525 3322]]\n",
      "\n",
      "Feature Importance (After Dropping Weak Predictors):\n",
      "                             Feature  Coefficient\n",
      "0                             score     1.732616\n",
      "2       assessment_completion_ratio     1.686868\n",
      "3                  total_vle_clicks     0.635760\n",
      "18  HLE_Post Graduate Qualification     0.592597\n",
      "10         Region_South East Region     0.315044\n",
      "16             HLE_HE Qualification     0.284819\n",
      "7               Region_North Region     0.272467\n",
      "17              HLE_No Formal quals     0.265608\n",
      "11              Region_South Region     0.239631\n",
      "12         Region_South West Region     0.204448\n",
      "5       Region_East Midlands Region     0.119034\n",
      "14      Region_West Midlands Region    -0.030990\n",
      "15          Region_Yorkshire Region    -0.034431\n",
      "19                  Age group_35-55    -0.052233\n",
      "6              Region_London Region    -0.079273\n",
      "1               Credit Distribution    -0.087163\n",
      "13                     Region_Wales    -0.128822\n",
      "8       Region_North Western Region    -0.187332\n",
      "4                          Gender_M    -0.213096\n",
      "9                   Region_Scotland    -0.278860\n",
      "25                  code_module_GGG    -0.969995\n",
      "20                  code_module_BBB    -1.128147\n",
      "23                  code_module_EEE    -1.411693\n",
      "22                  code_module_DDD    -1.493292\n",
      "24                  code_module_FFF    -1.818366\n",
      "21                  code_module_CCC    -2.003618\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score, confusion_matrix, f1_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# -----------------------------------\n",
    "# 1️⃣ Feature Selection - Drop Weak Predictors\n",
    "# -----------------------------------\n",
    "drop_columns = [\n",
    "    \"Region_Ireland\", \"HLE_Lower Than A Level\", \"Age group_55<=\"\n",
    "]\n",
    "\n",
    "# Drop weak features\n",
    "X_encoded = X_encoded.drop(columns=drop_columns, errors=\"ignore\")\n",
    "\n",
    "# -----------------------------------\n",
    "# 2️⃣ Standardize Numerical Features (Re-run after dropping)\n",
    "# -----------------------------------\n",
    "scaler = StandardScaler()\n",
    "numerical_features = ['score', 'Credit Distribution', 'assessment_completion_ratio', 'total_vle_clicks']\n",
    "X_encoded[numerical_features] = scaler.fit_transform(X_encoded[numerical_features])\n",
    "\n",
    "# -----------------------------------\n",
    "# 3️⃣ Split Data into Training and Test Sets\n",
    "# -----------------------------------\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_encoded, y, test_size=0.25, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# -----------------------------------\n",
    "# 4️⃣ Train Logistic Regression Model\n",
    "# -----------------------------------\n",
    "clf_lr = LogisticRegression(\n",
    "    max_iter=1000, \n",
    "    class_weight='balanced',  # Handling class imbalance\n",
    "    random_state=42\n",
    ")\n",
    "clf_lr.fit(X_train, y_train)\n",
    "y_pred_lr = clf_lr.predict(X_test)\n",
    "\n",
    "# -----------------------------------\n",
    "# 5️⃣ Model Evaluation\n",
    "# -----------------------------------\n",
    "accuracy_lr = accuracy_score(y_test, y_pred_lr)\n",
    "balanced_accuracy_lr = balanced_accuracy_score(y_test, y_pred_lr)\n",
    "f1_lr = f1_score(y_test, y_pred_lr)\n",
    "cm_lr = confusion_matrix(y_test, y_pred_lr)\n",
    "\n",
    "print(\"\\nModel Performance After Dropping Weak Predictors:\")\n",
    "print(\"Logistic Regression Accuracy:\", accuracy_lr)\n",
    "print(\"Logistic Regression Balanced Accuracy:\", balanced_accuracy_lr)\n",
    "print(\"Logistic Regression F1 Score:\", f1_lr)\n",
    "print(\"Logistic Regression Confusion Matrix:\\n\", cm_lr)\n",
    "\n",
    "# -----------------------------------\n",
    "# 6️⃣ Feature Importance After Dropping\n",
    "# -----------------------------------\n",
    "feature_importance = pd.DataFrame({\n",
    "    \"Feature\": X_encoded.columns,\n",
    "    \"Coefficient\": clf_lr.coef_[0]\n",
    "}).sort_values(by=\"Coefficient\", ascending=False)\n",
    "\n",
    "print(\"\\nFeature Importance (After Dropping Weak Predictors):\\n\", feature_importance)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Logistic Regression After Hyperparameter Tuning**\n",
    "✅ Used **GridSearchCV** to find the best `C` value for regularization.  \n",
    "✅ The best `C` value found was **0.001**, meaning stronger regularization.  \n",
    "✅ **Retrained Logistic Regression** with the optimized `C`.\n",
    "\n",
    "#### **Model Performance After Tuning `C`**\n",
    "- **Best C Value Found**: **0.001**\n",
    "\n",
    "- **Accuracy**: **85.42%** ⬆ (Improved after feature selection)\n",
    "- **Balanced Accuracy**: **83.62%** (Maintained improvement)\n",
    "- **F1 Score**: **89.27%**\n",
    "- **Confusion Matrix**:\n",
    "  - **False Positives (FP)**: **374** ⬆ (More students incorrectly predicted to pass)\n",
    "\n",
    "  - **False Negatives (FN)**: **444** ⬇ (**Reduced compared to feature selection model**)\n",
    "\n",
    "#### **Key Observations**\n",
    "- **Accuracy improved from 84.67% to 85.42%** after tuning `C`.\n",
    "\n",
    "- **False Negatives decreased** compared to the feature selection model (from 525 to 444).\n",
    "- **False Positives increased slightly**, meaning more failing students were misclassified as passing.\n",
    "- **Overall, this is the best-performing model so far** in terms of accuracy and balance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best C Value Found: 0.001\n",
      "\n",
      "Model Performance After Tuning `C`:\n",
      "Logistic Regression Accuracy: 0.8541889483065954\n",
      "Logistic Regression Balanced Accuracy: 0.8362234953800805\n",
      "Logistic Regression F1 Score: 0.892707240293809\n",
      "Logistic Regression Confusion Matrix:\n",
      " [[1389  374]\n",
      " [ 444 3403]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score, f1_score, confusion_matrix\n",
    "\n",
    "# -----------------------------------\n",
    "# 1️⃣ Hyperparameter Tuning - Optimize `C`\n",
    "# -----------------------------------\n",
    "param_grid = {\"C\": [0.001, 0.01, 0.1, 1, 10, 100]}\n",
    "grid_search = GridSearchCV(\n",
    "    LogisticRegression(max_iter=1000, class_weight=\"balanced\", solver=\"saga\"),\n",
    "    param_grid, cv=5, scoring=\"accuracy\"\n",
    ")\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "best_C = grid_search.best_params_[\"C\"]\n",
    "print(f\"Best C Value Found: {best_C}\")\n",
    "\n",
    "# -----------------------------------\n",
    "# 2️⃣ Retrain Logistic Regression with Best `C`\n",
    "# -----------------------------------\n",
    "clf_lr_tuned = LogisticRegression(C=best_C, max_iter=1000, class_weight=\"balanced\", solver=\"saga\")\n",
    "clf_lr_tuned.fit(X_train, y_train)\n",
    "y_pred_tuned = clf_lr_tuned.predict(X_test)\n",
    "\n",
    "# -----------------------------------\n",
    "# 3️⃣ Model Evaluation After Tuning\n",
    "# -----------------------------------\n",
    "accuracy_tuned = accuracy_score(y_test, y_pred_tuned)\n",
    "balanced_accuracy_tuned = balanced_accuracy_score(y_test, y_pred_tuned)\n",
    "f1_tuned = f1_score(y_test, y_pred_tuned)\n",
    "cm_tuned = confusion_matrix(y_test, y_pred_tuned)\n",
    "\n",
    "print(\"\\nModel Performance After Tuning `C`:\")\n",
    "print(\"Logistic Regression Accuracy:\", accuracy_tuned)\n",
    "print(\"Logistic Regression Balanced Accuracy:\", balanced_accuracy_tuned)\n",
    "print(\"Logistic Regression F1 Score:\", f1_tuned)\n",
    "print(\"Logistic Regression Confusion Matrix:\\n\", cm_tuned)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **🚀 Comparison of Logistic Regression Models**\n",
    "| **Model Version**            | **Accuracy** | **Balanced Accuracy** | **F1 Score** | **False Positives (FP)** | **False Negatives (FN)** |\n",
    "|------------------------------|-------------|----------------------|-------------|------------------|------------------|\n",
    "| **Baseline Model**           | **86.13%**  | **82.21%**           | **90.17%**  | **500**          | **278**          |\n",
    "| **Feature Selection Model**  | **84.67%**  | **83.68%** ⬆        | **88.54%**  | **335** ⬇        | **525** ⬆        |\n",
    "| **Tuned `C` Model (Best)**   | **85.42%**  | **83.62%** ⬆        | **89.27%**  | **374** ⬆        | **444** ⬇        |\n",
    "\n",
    "### **Key Takeaways**\n",
    "- **Baseline Model had the highest accuracy (86.13%)** but suffered from **high false positives (500)**.\n",
    "\n",
    "- **Feature Selection Model improved balance (83.68%)** but introduced **more false negatives (525)**.\n",
    "- **Tuned `C` Model is the best balance of accuracy and generalization** (85.42% accuracy, 83.62% balanced accuracy).\n",
    "- **False Positives increased slightly** after tuning, meaning more failing students were misclassified as passing.\n",
    "- **False Negatives significantly improved** from 525 → 444, meaning fewer passing students were misclassified as failing.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
