{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cost sensitive\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    id_student code_module  score Gender                Region  \\\n",
      "0        11391         AAA   82.0      M   East Anglian Region   \n",
      "1        28400         AAA   66.4      F              Scotland   \n",
      "3        31604         AAA   76.0      F     South East Region   \n",
      "4        32885         AAA   54.4      F  West Midlands Region   \n",
      "5        38053         AAA   68.0      M                 Wales   \n",
      "6        45462         AAA   68.0      M              Scotland   \n",
      "7        45642         AAA   72.4      F  North Western Region   \n",
      "8        52130         AAA   71.4      F   East Anglian Region   \n",
      "9        53025         AAA   78.0      M          North Region   \n",
      "10       57506         AAA   74.0      M          South Region   \n",
      "\n",
      "                            HLE Age group  Credit Distribution  \\\n",
      "0              HE Qualification      55<=                  240   \n",
      "1              HE Qualification     35-55                   60   \n",
      "3         A Level or Equivalent     35-55                   60   \n",
      "4            Lower Than A Level      0-35                   60   \n",
      "5         A Level or Equivalent     35-55                   60   \n",
      "6              HE Qualification      0-35                   60   \n",
      "7         A Level or Equivalent      0-35                  120   \n",
      "8         A Level or Equivalent      0-35                   90   \n",
      "9   Post Graduate Qualification      55<=                   60   \n",
      "10           Lower Than A Level     35-55                   60   \n",
      "\n",
      "    assessment_completion_ratio  total_vle_clicks  target  \n",
      "0                      0.833333             934.0       1  \n",
      "1                      0.833333            1435.0       1  \n",
      "3                      0.833333            2158.0       1  \n",
      "4                      0.833333            1034.0       1  \n",
      "5                      0.833333            2445.0       1  \n",
      "6                      0.833333            1492.0       1  \n",
      "7                      0.833333            1428.0       1  \n",
      "8                      0.833333            1894.0       1  \n",
      "9                      0.833333            3158.0       1  \n",
      "10                     0.833333            1319.0       1  \n",
      "Number of rows in df_final: 22437\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "\n",
    "# ============================\n",
    "# Data Loading and Merging\n",
    "# ============================\n",
    "\n",
    "# 1. Load your CSV files into DataFrames\n",
    "df_assessments = pd.read_csv(\"assessments.csv\")\n",
    "df_courses = pd.read_csv(\"courses.csv\")\n",
    "df_studentAssessment = pd.read_csv(\"studentAssessment.csv\")\n",
    "df_studentInfo = pd.read_csv(\"studentInfo.csv\")\n",
    "df_studentRegistration = pd.read_csv(\"studentRegistration.csv\")\n",
    "df_studentVle = pd.read_csv(\"studentVle.csv\")\n",
    "df_vle = pd.read_csv(\"vle.csv\")\n",
    "\n",
    "# Count how many unique assessments exist for each module + presentation\n",
    "df_course_assess_count = (\n",
    "    df_assessments\n",
    "    .groupby([\"code_module\", \"code_presentation\"])[\"id_assessment\"]\n",
    "    .count()\n",
    "    .reset_index()\n",
    "    .rename(columns={\"id_assessment\": \"total_assessments\"})\n",
    ")\n",
    "\n",
    "# Count how many assessments each student attempted\n",
    "df_attempted_count = (\n",
    "    df_studentAssessment\n",
    "    .groupby(\"id_student\")[\"id_assessment\"]\n",
    "    .count()\n",
    "    .reset_index()\n",
    "    .rename(columns={\"id_assessment\": \"num_assessments_attempted\"})\n",
    ")\n",
    "\n",
    "# Compute average score for each student\n",
    "df_avg_score = (\n",
    "    df_studentAssessment\n",
    "    .groupby(\"id_student\")[\"score\"]\n",
    "    .mean()  # or .sum() if you prefer total score\n",
    "    .reset_index()\n",
    "    .rename(columns={\"score\": \"score\"})\n",
    ")\n",
    "\n",
    "df_vle_clicks = (\n",
    "    df_studentVle\n",
    "    .groupby(\"id_student\")[\"sum_click\"]\n",
    "    .sum()\n",
    "    .reset_index()\n",
    "    .rename(columns={\"sum_click\": \"total_vle_clicks\"})\n",
    ")\n",
    "\n",
    "# 3.1 Merge total_assessments (on code_module + code_presentation)\n",
    "df_merged = pd.merge(\n",
    "    df_studentInfo,\n",
    "    df_course_assess_count,\n",
    "    on=[\"code_module\", \"code_presentation\"],\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "# 3.2 Merge attempted_assessments & average_score (on id_student)\n",
    "df_merged = pd.merge(\n",
    "    df_merged,\n",
    "    df_attempted_count,\n",
    "    on=\"id_student\",\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "df_merged = pd.merge(\n",
    "    df_merged,\n",
    "    df_avg_score,\n",
    "    on=\"id_student\",\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "# 3.3 Merge total_vle_clicks (on id_student)\n",
    "df_merged = pd.merge(\n",
    "    df_merged,\n",
    "    df_vle_clicks,\n",
    "    on=\"id_student\",\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "# Replace NaN with 0 if needed\n",
    "df_merged[\"num_assessments_attempted\"] = df_merged[\"num_assessments_attempted\"].fillna(0)\n",
    "df_merged[\"total_assessments\"] = df_merged[\"total_assessments\"].fillna(0)\n",
    "df_merged[\"score\"] = df_merged[\"score\"].fillna(0)  # if missing, assume 0 or handle differently\n",
    "df_merged[\"total_vle_clicks\"] = df_merged[\"total_vle_clicks\"].fillna(0)\n",
    "\n",
    "# Compute assessment_completion_ratio safely\n",
    "def completion_ratio(row):\n",
    "    if row[\"total_assessments\"] == 0:\n",
    "        return 0\n",
    "    return row[\"num_assessments_attempted\"] / row[\"total_assessments\"]\n",
    "\n",
    "df_merged[\"assessment_completion_ratio\"] = df_merged.apply(completion_ratio, axis=1)\n",
    "\n",
    "# Filter out withdrawn\n",
    "df_merged = df_merged[\n",
    "    (df_merged[\"final_result\"] != \"Withdrawn\") \n",
    "].copy()\n",
    "\n",
    "# Create binary target (Pass/Distinction=1, Fail=0)\n",
    "df_merged[\"target\"] = df_merged[\"final_result\"].apply(\n",
    "    lambda x: 1 if x in [\"Pass\", \"Distinction\"] else 0\n",
    ")\n",
    "\n",
    "# Rename columns for clarity\n",
    "df_merged.rename(\n",
    "    columns={\n",
    "        \"highest_education\": \"HLE\",\n",
    "        \"age_band\": \"Age group\",\n",
    "        \"studied_credits\": \"Credit Distribution\",\n",
    "        \"gender\": \"Gender\",\n",
    "        \"region\": \"Region\"\n",
    "    },\n",
    "    inplace=True\n",
    ")\n",
    "\n",
    "# ---------------------------\n",
    "# Final DataFrame including module\n",
    "# ---------------------------\n",
    "df_final = df_merged[\n",
    "    [\n",
    "        \"id_student\",\n",
    "        \"code_module\",            # <-- include the module feature here\n",
    "        \"score\",\n",
    "        \"Gender\",\n",
    "        \"Region\",\n",
    "        \"HLE\",\n",
    "        \"Age group\",\n",
    "        \"Credit Distribution\",\n",
    "        \"assessment_completion_ratio\",\n",
    "        \"total_vle_clicks\",\n",
    "        \"target\"\n",
    "    ]\n",
    "].copy()\n",
    "\n",
    "print(df_final.head(10))\n",
    "print(\"Number of rows in df_final:\", len(df_final))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====== Decision Tree Performance (Cost-Sensitive) ======\n",
      "\n",
      "Decision Tree Accuracy: 0.771301247771836\n",
      "Decision Tree Balanced Accuracy: 0.814963992096441\n",
      "Decision Tree F1 Score: 0.8070386524289367\n",
      "Decision Tree Confusion Matrix:\n",
      " [[1644  119]\n",
      " [1164 2683]]\n",
      "\n",
      "====== Random Forest Performance (Cost-Sensitive) ======\n",
      "\n",
      "Random Forest Accuracy: 0.6698752228163993\n",
      "Random Forest Balanced Accuracy: 0.7503820628548503\n",
      "Random Forest F1 Score: 0.6891574353810004\n",
      "Random Forest Confusion Matrix:\n",
      " [[1705   58]\n",
      " [1794 2053]]\n",
      "\n",
      "Random Forest OOB Score: 0.6507398823319664\n",
      "\n",
      "====== AdaBoost Performance (Cost-Sensitive) ======\n",
      "\n",
      "AdaBoost Accuracy: 0.8629233511586453\n",
      "AdaBoost Balanced Accuracy: 0.8246166728175162\n",
      "AdaBoost F1 Score: 0.9027444036929303\n",
      "AdaBoost Confusion Matrix:\n",
      " [[1272  491]\n",
      " [ 278 3569]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score, confusion_matrix, f1_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "\n",
    "# ===========================\n",
    "# Define Features & Target\n",
    "# ===========================\n",
    "features = [\n",
    "    'score', 'Gender', 'Region', 'HLE', 'Age group',\n",
    "    'Credit Distribution', 'assessment_completion_ratio', 'total_vle_clicks',\n",
    "    'code_module'  # include module\n",
    "]\n",
    "\n",
    "X = df_final[features]\n",
    "y = df_final['target']\n",
    "\n",
    "# ===========================\n",
    "# One-Hot Encode Categorical Features\n",
    "# ===========================\n",
    "X_encoded = pd.get_dummies(\n",
    "    X, \n",
    "    columns=['Gender', 'Region', 'HLE', 'Age group', 'code_module'], \n",
    "    drop_first=True\n",
    ")\n",
    "\n",
    "# ===========================\n",
    "# Split Data into Train & Test\n",
    "# ===========================\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_encoded, y, test_size=0.25, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# ===========================\n",
    "# Apply Cost-Sensitive Learning\n",
    "# ===========================\n",
    "\n",
    "# Define class weights (Higher weight for failing students)\n",
    "class_weights = {0: 2, 1: 1}  # Higher penalty for failing students\n",
    "\n",
    "# Initialize models with class weights\n",
    "models = {\n",
    "    \"Decision Tree\": DecisionTreeClassifier(max_depth=3, class_weight=class_weights, random_state=42),\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=100, max_depth=3, bootstrap=True, \n",
    "                                            oob_score=True, class_weight=class_weights, random_state=42),\n",
    "    \"AdaBoost\": AdaBoostClassifier(\n",
    "        estimator=DecisionTreeClassifier(max_depth=1, class_weight=class_weights, random_state=42),\n",
    "        n_estimators=100, random_state=42)\n",
    "}\n",
    "\n",
    "# ===========================\n",
    "# Train & Evaluate Models\n",
    "# ===========================\n",
    "for model_name, model in models.items():\n",
    "    print(f\"\\n====== {model_name} Performance (Cost-Sensitive) ======\\n\")\n",
    "    \n",
    "    # Train model\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predictions\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # General Performance Metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    balanced_accuracy = balanced_accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    print(f\"{model_name} Accuracy:\", accuracy)\n",
    "    print(f\"{model_name} Balanced Accuracy:\", balanced_accuracy)\n",
    "    print(f\"{model_name} F1 Score:\", f1)\n",
    "    print(f\"{model_name} Confusion Matrix:\\n\", cm)\n",
    "\n",
    "    # Special case: Print OOB Score for Random Forest\n",
    "    if model_name == \"Random Forest\":\n",
    "        print(\"\\nRandom Forest OOB Score:\", model.oob_score_)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
